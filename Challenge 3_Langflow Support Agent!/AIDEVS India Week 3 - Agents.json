{"icon_bg_color": null, "updated_at": "2024-10-07T09:25:19+00:00", "webhook": false, "id": "595d6bce-efe5-4124-94fa-481467450e40", "name": "AIDEVS India Week 3 - Agents", "description": "Crafting Conversations, One Node at a Time.", "icon": null, "is_component": false, "endpoint_name": null, "data": {"nodes": [{"id": "ToolCallingAgent-YNHfV", "type": "genericNode", "position": {"x": 1010.9155297354139, "y": -711.804767858177}, "data": {"type": "ToolCallingAgent", "node": {"template": {"_type": "Component", "chat_history": {"trace_as_input": true, "trace_as_metadata": true, "list": true, "required": false, "placeholder": "", "show": true, "value": "", "name": "chat_history", "display_name": "Chat History", "advanced": false, "input_types": ["Data"], "dynamic": false, "info": "", "title_case": false, "type": "other", "_input_type": "DataInput"}, "llm": {"trace_as_metadata": true, "list": false, "required": true, "placeholder": "", "show": true, "value": "", "name": "llm", "display_name": "Language Model", "advanced": false, "input_types": ["LanguageModel"], "dynamic": false, "info": "", "title_case": false, "type": "other", "_input_type": "HandleInput"}, "tools": {"trace_as_metadata": true, "list": true, "required": false, "placeholder": "", "show": true, "value": "", "name": "tools", "display_name": "Tools", "advanced": false, "input_types": ["Tool", "BaseTool"], "dynamic": false, "info": "", "title_case": false, "type": "other", "_input_type": "HandleInput"}, "code": {"type": "code", "required": true, "placeholder": "", "list": false, "show": true, "multiline": true, "value": "from typing import Optional, List\n\nfrom langchain.agents import create_tool_calling_agent\nfrom langchain_core.prompts import ChatPromptTemplate, PromptTemplate, HumanMessagePromptTemplate\nfrom langflow.base.agents.agent import LCToolsAgentComponent\nfrom langflow.inputs import MultilineInput\nfrom langflow.inputs.inputs import HandleInput, DataInput\nfrom langflow.schema import Data\n\n\nclass ToolCallingAgentComponent(LCToolsAgentComponent):\n    display_name: str = \"Tool Calling Agent\"\n    description: str = \"Agent that uses tools\"\n    icon = \"LangChain\"\n    beta = True\n    name = \"ToolCallingAgent\"\n\n    inputs = LCToolsAgentComponent._base_inputs + [\n        HandleInput(name=\"llm\", display_name=\"Language Model\", input_types=[\"LanguageModel\"], required=True),\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"System Prompt\",\n            info=\"System prompt for the agent.\",\n            value=\"You are a helpful assistant\",\n        ),\n        MultilineInput(\n            name=\"user_prompt\", display_name=\"Prompt\", info=\"This prompt must contain 'input' key.\", value=\"{input}\"\n        ),\n        DataInput(name=\"chat_history\", display_name=\"Chat History\", is_list=True, advanced=True),\n    ]\n\n    def get_chat_history_data(self) -> Optional[List[Data]]:\n        return self.chat_history\n\n    def create_agent_runnable(self):\n        if \"input\" not in self.user_prompt:\n            raise ValueError(\"Prompt must contain 'input' key.\")\n        messages = [\n            (\"system\", self.system_prompt),\n            (\"placeholder\", \"{chat_history}\"),\n            HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[\"input\"], template=self.user_prompt)),\n            (\"placeholder\", \"{agent_scratchpad}\"),\n        ]\n        prompt = ChatPromptTemplate.from_messages(messages)\n        return create_tool_calling_agent(self.llm, self.tools, prompt)\n", "fileTypes": [], "file_path": "", "password": false, "name": "code", "advanced": true, "dynamic": true, "info": "", "load_from_db": false, "title_case": false}, "handle_parsing_errors": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "value": true, "name": "handle_parsing_errors", "display_name": "Handle Parse Errors", "advanced": true, "dynamic": false, "info": "", "title_case": false, "type": "bool", "_input_type": "BoolInput"}, "input_value": {"trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "value": "", "name": "input_value", "display_name": "Input", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "max_iterations": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "value": "15", "name": "max_iterations", "display_name": "Max Iterations", "advanced": false, "dynamic": false, "info": "", "title_case": false, "type": "int", "_input_type": "IntInput"}, "system_prompt": {"trace_as_input": true, "multiline": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "value": "", "name": "system_prompt", "display_name": "System Prompt", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "System prompt for the agent.", "title_case": false, "type": "str", "_input_type": "MultilineInput"}, "user_prompt": {"trace_as_input": true, "multiline": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "value": "{input}", "name": "user_prompt", "display_name": "Prompt", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "This prompt must contain 'input' key.", "title_case": false, "type": "str", "_input_type": "MultilineInput"}, "verbose": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "value": true, "name": "verbose", "display_name": "Verbose", "advanced": true, "dynamic": false, "info": "", "title_case": false, "type": "bool", "_input_type": "BoolInput"}}, "description": "Agent that uses tools", "icon": "LangChain", "base_classes": ["AgentExecutor", "Message"], "display_name": "Tool Calling Agent", "documentation": "", "custom_fields": {}, "output_types": [], "pinned": false, "conditional_paths": [], "frozen": false, "outputs": [{"types": ["AgentExecutor"], "selected": "AgentExecutor", "name": "agent", "display_name": "Agent", "method": "build_agent", "value": "__UNDEFINED__", "cache": true, "hidden": true}, {"types": ["Message"], "selected": "Message", "name": "response", "display_name": "Response", "method": "message_response", "value": "__UNDEFINED__", "cache": true}], "field_order": ["input_value", "handle_parsing_errors", "verbose", "max_iterations", "tools", "llm", "system_prompt", "user_prompt", "chat_history"], "beta": true, "edited": false, "lf_version": "1.0.18"}, "id": "ToolCallingAgent-YNHfV"}, "selected": false, "width": 384, "height": 618, "positionAbsolute": {"x": 1010.9155297354139, "y": -711.804767858177}, "dragging": false}, {"id": "ChatInput-N93NG", "type": "genericNode", "position": {"x": -50.62164754917296, "y": -727.3385554788658}, "data": {"type": "ChatInput", "node": {"template": {"_type": "Component", "files": {"trace_as_metadata": true, "file_path": "", "fileTypes": ["txt", "md", "mdx", "csv", "json", "yaml", "yml", "xml", "html", "htm", "pdf", "docx", "py", "sh", "sql", "js", "ts", "tsx", "jpg", "jpeg", "png", "bmp", "image"], "list": true, "required": false, "placeholder": "", "show": true, "value": "", "name": "files", "display_name": "Files", "advanced": true, "dynamic": false, "info": "Files to be sent with the message.", "title_case": false, "type": "file", "_input_type": "FileInput"}, "code": {"type": "code", "required": true, "placeholder": "", "list": false, "show": true, "multiline": true, "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom langflow.memory import store_message\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_NAME_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n", "fileTypes": [], "file_path": "", "password": false, "name": "code", "advanced": true, "dynamic": true, "info": "", "load_from_db": false, "title_case": false}, "input_value": {"trace_as_input": true, "multiline": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "value": "How does Langflow implement API key functionality for user authentication, and what are the different methods available for generating and using these API keys in API requests?", "name": "input_value", "display_name": "Text", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "Message to be passed as input.", "title_case": false, "type": "str", "_input_type": "MultilineInput"}, "sender": {"trace_as_metadata": true, "options": ["Machine", "User"], "combobox": false, "required": false, "placeholder": "", "show": true, "value": "User", "name": "sender", "display_name": "Sender Type", "advanced": true, "dynamic": false, "info": "Type of sender.", "title_case": false, "type": "str", "_input_type": "DropdownInput"}, "sender_name": {"trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "value": "User", "name": "sender_name", "display_name": "Sender Name", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "Name of the sender.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "session_id": {"trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "value": "", "name": "session_id", "display_name": "Session ID", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "The session ID of the chat. If empty, the current session ID parameter will be used.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "should_store_message": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "value": true, "name": "should_store_message", "display_name": "Store Messages", "advanced": true, "dynamic": false, "info": "Store the message in the history.", "title_case": false, "type": "bool", "_input_type": "BoolInput"}}, "description": "Get chat inputs from the Playground.", "icon": "ChatInput", "base_classes": ["Message"], "display_name": "Chat Input", "documentation": "", "custom_fields": {}, "output_types": [], "pinned": false, "conditional_paths": [], "frozen": false, "outputs": [{"types": ["Message"], "selected": "Message", "name": "message", "display_name": "Message", "method": "message_response", "value": "__UNDEFINED__", "cache": true}], "field_order": ["input_value", "should_store_message", "sender", "sender_name", "session_id", "files"], "beta": false, "edited": false, "lf_version": "1.0.18"}, "id": "ChatInput-N93NG"}, "selected": false, "width": 384, "height": 302, "positionAbsolute": {"x": -50.62164754917296, "y": -727.3385554788658}, "dragging": false}, {"id": "ChatOutput-rvvAN", "type": "genericNode", "position": {"x": 1519.0996640534418, "y": -596.7086248812136}, "data": {"type": "ChatOutput", "node": {"template": {"_type": "Component", "code": {"type": "code", "required": true, "placeholder": "", "list": false, "show": true, "multiline": true, "value": "from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.memory import store_message\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n", "fileTypes": [], "file_path": "", "password": false, "name": "code", "advanced": true, "dynamic": true, "info": "", "load_from_db": false, "title_case": false}, "data_template": {"trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "data_template", "value": "{text}", "display_name": "Data Template", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "input_value": {"trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "input_value", "value": "", "display_name": "Text", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "Message to be passed as output.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "sender": {"trace_as_metadata": true, "options": ["Machine", "User"], "combobox": false, "required": false, "placeholder": "", "show": true, "name": "sender", "value": "Machine", "display_name": "Sender Type", "advanced": true, "dynamic": false, "info": "Type of sender.", "title_case": false, "type": "str", "_input_type": "DropdownInput"}, "sender_name": {"trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "sender_name", "value": "AI", "display_name": "Sender Name", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "Name of the sender.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "session_id": {"trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "session_id", "value": "", "display_name": "Session ID", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "The session ID of the chat. If empty, the current session ID parameter will be used.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "should_store_message": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "should_store_message", "value": true, "display_name": "Store Messages", "advanced": true, "dynamic": false, "info": "Store the message in the history.", "title_case": false, "type": "bool", "_input_type": "BoolInput"}}, "description": "Display a chat message in the Playground.", "icon": "ChatOutput", "base_classes": ["Message"], "display_name": "Chat Output", "documentation": "", "custom_fields": {}, "output_types": [], "pinned": false, "conditional_paths": [], "frozen": false, "outputs": [{"types": ["Message"], "selected": "Message", "name": "message", "display_name": "Message", "method": "message_response", "value": "__UNDEFINED__", "cache": true}], "field_order": ["input_value", "should_store_message", "sender", "sender_name", "session_id", "data_template"], "beta": false, "edited": false, "lf_version": "1.0.18"}, "id": "ChatOutput-rvvAN", "description": "Display a chat message in the Playground.", "display_name": "Chat Output"}, "selected": false, "width": 384, "height": 302, "positionAbsolute": {"x": 1519.0996640534418, "y": -596.7086248812136}, "dragging": false}, {"id": "Prompt-2dgP5", "type": "genericNode", "position": {"x": 421.88848615068207, "y": -745.0400588207334}, "data": {"type": "Prompt", "node": {"template": {"_type": "Component", "code": {"type": "code", "required": true, "placeholder": "", "list": false, "show": true, "multiline": true, "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n", "fileTypes": [], "file_path": "", "password": false, "name": "code", "advanced": true, "dynamic": true, "info": "", "load_from_db": false, "title_case": false}, "template": {"trace_as_input": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "template", "value": "# Langflow Technical Support Agent\n\nYou are an advanced AI agent specializing in technical support for Langflow. Your primary function is to assist users with Langflow-related queries, utilizing a comprehensive knowledge base and a sophisticated problem-matching system.\n", "display_name": "Template", "advanced": false, "dynamic": false, "info": "", "title_case": false, "type": "prompt", "_input_type": "PromptInput", "load_from_db": false}}, "description": "Create a prompt template with dynamic variables.", "icon": "prompts", "is_input": null, "is_output": null, "is_composition": null, "base_classes": ["Message"], "name": "", "display_name": "Prompt", "documentation": "", "custom_fields": {"template": []}, "output_types": [], "full_path": null, "pinned": false, "conditional_paths": [], "frozen": false, "outputs": [{"types": ["Message"], "selected": "Message", "name": "prompt", "hidden": null, "display_name": "Prompt Message", "method": "build_prompt", "value": "__UNDEFINED__", "cache": true}], "field_order": ["template"], "beta": false, "error": null, "edited": false, "lf_version": "1.0.18"}, "id": "Prompt-2dgP5", "description": "Create a prompt template with dynamic variables.", "display_name": "Prompt"}, "selected": false, "width": 384, "height": 330, "positionAbsolute": {"x": 421.88848615068207, "y": -745.0400588207334}, "dragging": false}, {"id": "OpenAIModel-mIrVZ", "type": "genericNode", "position": {"x": 427.21087464468394, "y": -391.25319872344664}, "data": {"type": "OpenAIModel", "node": {"template": {"_type": "Component", "api_key": {"load_from_db": false, "required": false, "placeholder": "", "show": true, "value": null, "name": "api_key", "display_name": "OpenAI API Key", "advanced": false, "input_types": [], "dynamic": false, "info": "The OpenAI API Key to use for the OpenAI model.", "title_case": false, "password": true, "type": "str"}, "code": {"type": "code", "required": true, "placeholder": "", "list": false, "show": true, "multiline": true, "value": "import operator\r\nfrom functools import reduce\r\n\r\nfrom langchain_openai import ChatOpenAI\r\nfrom pydantic.v1 import SecretStr\r\n\r\nfrom langflow.base.constants import STREAM_INFO_TEXT\r\nfrom langflow.base.models.model import LCModelComponent\r\nfrom langflow.base.models.openai_constants import MODEL_NAMES\r\nfrom langflow.field_typing import LanguageModel\r\nfrom langflow.inputs import (\r\n    BoolInput,\r\n    DictInput,\r\n    DropdownInput,\r\n    FloatInput,\r\n    IntInput,\r\n    MessageInput,\r\n    SecretStrInput,\r\n    StrInput,\r\n)\r\n\r\nclass OpenAIModelComponent(LCModelComponent):\r\n    display_name = \"OpenAI\"\r\n    description = \"Generates text using OpenAI LLMs.\"\r\n    icon = \"OpenAI\"\r\n    name = \"OpenAIModel\"\r\n\r\n    inputs = [\r\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\r\n        IntInput(\r\n            name=\"max_tokens\",\r\n            display_name=\"Max Tokens\",\r\n            advanced=True,\r\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\r\n        ),\r\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\r\n        BoolInput(\r\n            name=\"json_mode\",\r\n            display_name=\"JSON Mode\",\r\n            advanced=True,\r\n            info=\"If True, it will output JSON regardless of passing a schema.\",\r\n        ),\r\n        DictInput(\r\n            name=\"output_schema\",\r\n            is_list=True,\r\n            display_name=\"Schema\",\r\n            advanced=True,\r\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\r\n        ),\r\n        DropdownInput(\r\n            name=\"model_name\", display_name=\"Model Name\", advanced=False, options=[\"gpt-4o-mini\"], value=\"gpt-4o-mini\"\r\n        ),\r\n        StrInput(\r\n            name=\"openai_api_base\",\r\n            display_name=\"OpenAI API Base\",\r\n            advanced=True,\r\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\r\n        ),\r\n        SecretStrInput(\r\n            name=\"api_key\",\r\n            display_name=\"OpenAI API Key\",\r\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\r\n            advanced=False,\r\n            value=\"OPENAI_API_KEY\",\r\n        ),\r\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\r\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\r\n        StrInput(\r\n            name=\"system_message\",\r\n            display_name=\"System Message\",\r\n            info=\"System message to pass to the model.\",\r\n            advanced=True,\r\n        ),\r\n        IntInput(\r\n            name=\"seed\",\r\n            display_name=\"Seed\",\r\n            info=\"The seed controls the reproducibility of the job.\",\r\n            advanced=True,\r\n            value=1,\r\n        ),\r\n    ]\r\n\r\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\r\n        # self.output_schema is a list of dictionaries\r\n        # let's convert it to a dictionary\r\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\r\n        openai_api_key = self.api_key\r\n        temperature = self.temperature\r\n        model_name: str = self.model_name\r\n        max_tokens = self.max_tokens\r\n        model_kwargs = self.model_kwargs or {}\r\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\r\n        json_mode = bool(output_schema_dict) or self.json_mode\r\n        seed = self.seed\r\n\r\n        if openai_api_key:\r\n            api_key = SecretStr(openai_api_key)\r\n        else:\r\n            api_key = None\r\n        output = ChatOpenAI(\r\n            max_tokens=max_tokens or None,\r\n            model_kwargs=model_kwargs,\r\n            model=model_name,\r\n            base_url=openai_api_base,\r\n            api_key=api_key,\r\n            temperature=temperature or 0.1,\r\n            seed=seed,\r\n        )\r\n        if json_mode:\r\n            if output_schema_dict:\r\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\r\n            else:\r\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\r\n\r\n        return output  # type: ignore\r\n\r\n    def _get_exception_message(self, e: Exception):\r\n        \"\"\"\r\n        Get a message from an OpenAI exception.\r\n\r\n        Args:\r\n            exception (Exception): The exception to get the message from.\r\n\r\n        Returns:\r\n            str: The message from the exception.\r\n        \"\"\"\r\n\r\n        try:\r\n            from openai import BadRequestError\r\n        except ImportError:\r\n            return\r\n        if isinstance(e, BadRequestError):\r\n            message = e.body.get(\"message\")  # type: ignore\r\n            if message:\r\n                return message\r\n        return", "fileTypes": [], "file_path": "", "password": false, "name": "code", "advanced": true, "dynamic": true, "info": "", "load_from_db": false, "title_case": false}, "input_value": {"trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "value": "", "name": "input_value", "display_name": "Input", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "", "title_case": false, "type": "str"}, "json_mode": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "value": false, "name": "json_mode", "display_name": "JSON Mode", "advanced": true, "dynamic": false, "info": "If True, it will output JSON regardless of passing a schema.", "title_case": false, "type": "bool"}, "max_tokens": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "value": "", "name": "max_tokens", "display_name": "Max Tokens", "advanced": true, "dynamic": false, "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.", "title_case": false, "type": "int"}, "model_kwargs": {"trace_as_input": true, "list": false, "required": false, "placeholder": "", "show": true, "value": {}, "name": "model_kwargs", "display_name": "Model Kwargs", "advanced": true, "dynamic": false, "info": "", "title_case": false, "type": "dict"}, "model_name": {"trace_as_metadata": true, "options": ["gpt-4o-mini"], "required": false, "placeholder": "", "show": true, "value": "gpt-4o-mini", "name": "model_name", "display_name": "Model Name", "advanced": false, "dynamic": false, "info": "", "title_case": false, "type": "str", "load_from_db": false}, "openai_api_base": {"trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "value": "", "name": "openai_api_base", "display_name": "OpenAI API Base", "advanced": true, "dynamic": false, "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.", "title_case": false, "type": "str"}, "output_schema": {"trace_as_input": true, "list": true, "required": false, "placeholder": "", "show": true, "value": {}, "name": "output_schema", "display_name": "Schema", "advanced": true, "dynamic": false, "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.", "title_case": false, "type": "dict"}, "seed": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "value": 1, "name": "seed", "display_name": "Seed", "advanced": true, "dynamic": false, "info": "The seed controls the reproducibility of the job.", "title_case": false, "type": "int"}, "stream": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "value": false, "name": "stream", "display_name": "Stream", "advanced": true, "dynamic": false, "info": "Stream the response from the model. Streaming works only in Chat.", "title_case": false, "type": "bool"}, "system_message": {"trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "value": "", "name": "system_message", "display_name": "System Message", "advanced": true, "dynamic": false, "info": "System message to pass to the model.", "title_case": false, "type": "str"}, "temperature": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "value": 0.1, "name": "temperature", "display_name": "Temperature", "advanced": false, "dynamic": false, "info": "", "title_case": false, "type": "float"}}, "description": "Generates text using OpenAI LLMs.", "icon": "OpenAI", "base_classes": ["LanguageModel", "Message"], "display_name": "OpenAI", "documentation": "", "custom_fields": {}, "output_types": [], "pinned": false, "conditional_paths": [], "frozen": false, "outputs": [{"types": ["Message"], "selected": "Message", "name": "text_output", "display_name": "Text", "method": "text_response", "value": "__UNDEFINED__", "cache": true}, {"types": ["LanguageModel"], "selected": "LanguageModel", "name": "model_output", "display_name": "Language Model", "method": "build_model", "value": "__UNDEFINED__", "cache": true}], "field_order": ["input_value", "max_tokens", "model_kwargs", "json_mode", "output_schema", "model_name", "openai_api_base", "api_key", "temperature", "stream", "system_message", "seed"], "beta": false, "edited": true, "official": false, "lf_version": "1.0.18"}, "id": "OpenAIModel-mIrVZ"}, "selected": false, "width": 384, "height": 605, "positionAbsolute": {"x": 427.21087464468394, "y": -391.25319872344664}, "dragging": false}, {"id": "TavilySearch-1Ar3w", "type": "genericNode", "position": {"x": 429.69522846464884, "y": -1261.5769539585406}, "data": {"type": "TavilySearch", "node": {"template": {"_type": "Component", "api_key": {"load_from_db": false, "required": true, "placeholder": "", "show": true, "name": "api_key", "value": null, "display_name": "Tavily API Key", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "Your Tavily API Key.", "title_case": false, "password": true, "type": "str", "_input_type": "SecretStrInput"}, "code": {"type": "code", "required": true, "placeholder": "", "list": false, "show": true, "multiline": true, "value": "import httpx\r\nfrom typing import List, Optional\r\nfrom pydantic import BaseModel, Field\r\nfrom langflow.base.langchain_utilities.model import LCToolComponent\r\nfrom langflow.inputs import SecretStrInput, MessageTextInput, DropdownInput, IntInput, BoolInput\r\nfrom langflow.schema import Data\r\nfrom langflow.field_typing import Tool\r\nfrom langchain.tools import StructuredTool\r\n\r\nclass TavilySearchToolComponent(LCToolComponent):\r\n    display_name = \"Tavily Search\"\r\n    description = \"Perform web searches using the Tavily API.\"\r\n    icon = \"search\"\r\n    name = \"TavilySearch\"\r\n    documentation = \"https://tavily.com/#api\"\r\n\r\n    inputs = [\r\n        SecretStrInput(\r\n            name=\"api_key\",\r\n            display_name=\"Tavily API Key\",\r\n            required=True,\r\n            info=\"Your Tavily API Key.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"query\",\r\n            display_name=\"Search Query\",\r\n            info=\"The search query you want to execute with Tavily.\",\r\n\r\n        ),\r\n        DropdownInput(\r\n            name=\"search_depth\",\r\n            display_name=\"Search Depth\",\r\n            info=\"The depth of the search.\",\r\n            options=[\"basic\", \"advanced\"],\r\n            value=\"basic\",\r\n        ),\r\n        DropdownInput(\r\n            name=\"topic\",\r\n            display_name=\"Search Topic\",\r\n            info=\"The category of the search.\",\r\n            options=[\"general\", \"news\"],\r\n            value=\"general\",\r\n        ),\r\n        IntInput(\r\n            name=\"max_results\",\r\n            display_name=\"Max Results\",\r\n            info=\"The maximum number of search results to return.\",\r\n            value=5,\r\n        ),\r\n        BoolInput(\r\n            name=\"include_images\",\r\n            display_name=\"Include Images\",\r\n            info=\"Include a list of query-related images in the response.\",\r\n            value=False,\r\n        ),\r\n        BoolInput(\r\n            name=\"include_answer\",\r\n            display_name=\"Include Answer\",\r\n            info=\"Include a short answer to original query.\",\r\n            value=False,\r\n        ),\r\n    ]\r\n\r\n    class TavilySearchSchema(BaseModel):\r\n        query: str = Field(..., description=\"The search query you want to execute with Tavily.\")\r\n        search_depth: str = Field(\"basic\", description=\"The depth of the search.\")\r\n        topic: str = Field(\"general\", description=\"The category of the search.\")\r\n        max_results: int = Field(5, description=\"The maximum number of search results to return.\")\r\n        include_images: bool = Field(False, description=\"Include a list of query-related images in the response.\")\r\n        include_answer: bool = Field(False, description=\"Include a short answer to original query.\")\r\n\r\n    def run_model(self) -> List[Data]:\r\n        return self._tavily_search(\r\n            self.query,\r\n            self.search_depth,\r\n            self.topic,\r\n            self.max_results,\r\n            self.include_images,\r\n            self.include_answer,\r\n        )\r\n\r\n    def build_tool(self) -> Tool:\r\n        return StructuredTool.from_function(\r\n            name=\"tavily_search\",\r\n            description=\"Perform a web search using the Tavily API.\",\r\n            func=self._tavily_search,\r\n            args_schema=self.TavilySearchSchema,\r\n        )\r\n\r\n    def _tavily_search(\r\n        self,\r\n        query: str,\r\n        search_depth: str = \"basic\",\r\n        topic: str = \"general\",\r\n        max_results: int = 5,\r\n        include_images: bool = False,\r\n        include_answer: bool = False,\r\n    ) -> List[Data]:\r\n        try:\r\n            url = \"https://api.tavily.com/search\"\r\n            headers = {\r\n                \"content-type\": \"application/json\",\r\n                \"accept\": \"application/json\",\r\n            }\r\n            payload = {\r\n                \"api_key\": self.api_key,\r\n                \"query\": query,\r\n                \"search_depth\": search_depth,\r\n                \"topic\": topic,\r\n                \"max_results\": max_results,\r\n                \"include_images\": include_images,\r\n                \"include_answer\": include_answer,\r\n            }\r\n\r\n            with httpx.Client() as client:\r\n                response = client.post(url, json=payload, headers=headers)\r\n            \r\n            response.raise_for_status()\r\n            search_results = response.json()\r\n\r\n            data_results = [\r\n                Data(\r\n                    data={\r\n                        \"title\": result.get(\"title\"),\r\n                        \"url\": result.get(\"url\"),\r\n                        \"content\": result.get(\"content\"),\r\n                        \"score\": result.get(\"score\"),\r\n                    }\r\n                )\r\n                for result in search_results.get(\"results\", [])\r\n            ]\r\n\r\n            if include_answer and search_results.get(\"answer\"):\r\n                data_results.insert(0, Data(data={\"answer\": search_results[\"answer\"]}))\r\n\r\n            if include_images and search_results.get(\"images\"):\r\n                data_results.append(Data(data={\"images\": search_results[\"images\"]}))\r\n\r\n            self.status = data_results\r\n            return data_results\r\n\r\n        except httpx.HTTPStatusError as e:\r\n            error_message = f\"HTTP error: {e.response.status_code} - {e.response.text}\"\r\n            self.status = error_message\r\n            return [Data(data={\"error\": error_message})]\r\n        except Exception as e:\r\n            error_message = f\"Unexpected error: {str(e)}\"\r\n            self.status = error_message\r\n            return [Data(data={\"error\": error_message})]", "fileTypes": [], "file_path": "", "password": false, "name": "code", "advanced": true, "dynamic": true, "info": "", "load_from_db": false, "title_case": false}, "include_answer": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "include_answer", "value": true, "display_name": "Include Answer", "advanced": false, "dynamic": false, "info": "Include a short answer to original query.", "title_case": false, "type": "bool", "_input_type": "BoolInput", "load_from_db": false}, "include_images": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "include_images", "value": true, "display_name": "Include Images", "advanced": false, "dynamic": false, "info": "Include a list of query-related images in the response.", "title_case": false, "type": "bool", "_input_type": "BoolInput", "load_from_db": false}, "max_results": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "max_results", "value": 7, "display_name": "Max Results", "advanced": true, "dynamic": false, "info": "The maximum number of search results to return.", "title_case": false, "type": "int", "_input_type": "IntInput"}, "query": {"trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "query", "value": "", "display_name": "Search Query", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "The search query you want to execute with Tavily.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "search_depth": {"trace_as_metadata": true, "options": ["basic", "advanced"], "combobox": false, "required": false, "placeholder": "", "show": true, "name": "search_depth", "value": "advanced", "display_name": "Search Depth", "advanced": true, "dynamic": false, "info": "The depth of the search.", "title_case": false, "type": "str", "_input_type": "DropdownInput", "load_from_db": false}, "topic": {"trace_as_metadata": true, "options": ["general", "news"], "combobox": false, "required": false, "placeholder": "", "show": true, "name": "topic", "value": "general", "display_name": "Search Topic", "advanced": true, "dynamic": false, "info": "The category of the search.", "title_case": false, "type": "str", "_input_type": "DropdownInput"}}, "description": "Perform web searches using the Tavily API.", "icon": "search", "base_classes": ["Data", "Tool"], "display_name": "Tavily Search", "documentation": "https://tavily.com/#api", "custom_fields": {}, "output_types": [], "pinned": false, "conditional_paths": [], "frozen": false, "outputs": [{"types": ["Data"], "selected": "Data", "name": "api_run_model", "display_name": "Data", "method": "run_model", "value": "__UNDEFINED__", "cache": true}, {"types": ["Tool"], "selected": "Tool", "name": "api_build_tool", "display_name": "Tool", "method": "build_tool", "value": "__UNDEFINED__", "cache": true}], "field_order": ["api_key", "query", "search_depth", "topic", "max_results", "include_images", "include_answer"], "beta": false, "edited": true, "lf_version": "1.0.18"}, "id": "TavilySearch-1Ar3w"}, "selected": false, "width": 384, "height": 491, "positionAbsolute": {"x": 429.69522846464884, "y": -1261.5769539585406}, "dragging": false}, {"id": "LangWatchEvaluatorComponent-lc31r", "type": "genericNode", "position": {"x": 2018.1907464472497, "y": -783.5610398861654}, "data": {"type": "LangWatchEvaluatorComponent", "node": {"template": {"_type": "Component", "context_data": {"trace_as_metadata": true, "list": false, "trace_as_input": true, "required": false, "placeholder": "", "show": true, "name": "context_data", "value": "", "display_name": "RAG Search Results (optional)", "advanced": false, "input_types": ["Data"], "dynamic": false, "info": "The data to be used as context for evaluation.", "title_case": false, "type": "other", "_input_type": "DataInput"}, "answer": {"trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "answer", "value": "", "display_name": "Answer", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "The generated answer to be evaluated.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "code": {"type": "code", "required": true, "placeholder": "", "list": false, "show": true, "multiline": true, "value": "import re\r\nfrom langflow.custom import Component\r\nfrom langflow.inputs import MessageTextInput, DataInput\r\nfrom langflow.schema.message import Message\r\nfrom langflow.template import Output\r\nfrom langflow.schema import Data\r\nimport langwatch\r\n\r\nclass LangWatchEvaluatorComponent(Component):\r\n    display_name = \"LangWatch Evaluator\"\r\n    description = \"Evaluates a question-answer pair using LangWatch and provides a trace URL.\"\r\n    icon = \"view\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"question\",\r\n            display_name=\"Question\",\r\n            info=\"The question to be evaluated.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"answer\",\r\n            display_name=\"Answer\",\r\n            info=\"The generated answer to be evaluated.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"ground_truth\",\r\n            display_name=\"Correct Answer\",\r\n            info=\"The expected correct answer.\",\r\n        ),\r\n        DataInput(\r\n            name=\"context_data\",\r\n            display_name=\"RAG Search Results (optional)\",\r\n            info=\"The data to be used as context for evaluation.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"user_email\",\r\n            display_name=\"User Email\",\r\n            info=\"The user email for the trace metadata.\",\r\n            advanced=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"user_name\",\r\n            display_name=\"Participant Name\",\r\n            info=\"Full name for identification in the trace metadata.\",\r\n            advanced=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"question_id\",\r\n            display_name=\"Question ID\",\r\n            info=\"The question ID for the trace metadata.\",\r\n            advanced=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Trace URL\", name=\"trace_url\", method=\"evaluate\"),\r\n    ]\r\n\r\n    async def evaluate(self) -> Data:\r\n        question = self.question\r\n        answer = self.answer\r\n        ground_truth = self.ground_truth\r\n        context_data = self.context_data\r\n        user_email = self.user_email if self.user_email else \"\"\r\n        question_id = self.question_id if self.question_id else \"\"\r\n        user_name = self.user_name if self.user_name else \"\"\r\n\r\n        # Validate email if provided\r\n        if user_email and not self.validate_email(user_email):\r\n            raise ValueError(f\"Invalid email address: {user_email}\")\r\n\r\n        langwatch.api_key = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0aW1lc3RhbXAiOjE3MjY2Njk3NTkyMjcsInJhbmQiOjAuMjg5OTc4Mjk4NzU2MzIzOTcsImlhdCI6MTcyNjY2OTc1OX0._ow7WQ5RSTlYE-HjdcouHUCoXf9nRnWHk4u9nfq4LIw'\r\n\r\n        trace = langwatch.trace(\r\n            metadata={\r\n                \"user_email\": user_email,\r\n                \"question_id\": question_id,\r\n                \"user_name\": user_name,\r\n            },\r\n            expected_output=ground_truth\r\n        )\r\n        \r\n        contexts = [item.text.replace(\"\\t\", \" \").replace(\"\\n\", \" \") for item in context_data[:5]] if context_data else []\r\n        rag_span = trace.span(type=\"rag\", name=\"LangWatch Evaluator\", input=question, contexts=contexts, output=answer)\r\n        rag_span.end()\r\n\r\n        trace.send_spans()\r\n\r\n        public_url = trace.share()\r\n        self.log(f\"See the trace at: {public_url}\")\r\n\r\n        self.status = Data(data={\"trace_url\": public_url})\r\n        return Data(data={\"trace_url\": public_url})\r\n        \r\n    def validate_email(self, email):\r\n        pattern = r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$'\r\n        return re.match(pattern, email) is not None", "fileTypes": [], "file_path": "", "password": false, "name": "code", "advanced": true, "dynamic": true, "info": "", "load_from_db": false, "title_case": false}, "ground_truth": {"trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "ground_truth", "value": "", "display_name": "Correct Answer", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "The expected correct answer.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "question": {"trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "question", "value": "", "display_name": "Question", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "The question to be evaluated.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "question_id": {"trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "question_id", "value": "", "display_name": "Question ID", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "The question ID for the trace metadata.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "user_email": {"trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "user_email", "value": "", "display_name": "User Email", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "The user email for the trace metadata.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "user_name": {"trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "user_name", "value": "", "display_name": "Participant Name", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "Full name for identification in the trace metadata.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}}, "description": "Evaluates a question-answer pair using LangWatch and provides a trace URL.", "icon": "view", "base_classes": ["Data"], "display_name": "Langwatch Evaluator", "documentation": "", "custom_fields": {}, "output_types": [], "pinned": false, "conditional_paths": [], "frozen": false, "outputs": [{"types": ["Data"], "selected": "Data", "name": "trace_url", "display_name": "Trace URL", "method": "evaluate", "value": "__UNDEFINED__", "cache": true}], "field_order": ["question", "answer", "ground_truth", "context_data", "user_email", "user_name", "question_id"], "beta": false, "edited": true, "lf_version": "1.0.18"}, "id": "LangWatchEvaluatorComponent-lc31r", "description": "Evaluates a question-answer pair using LangWatch and provides a trace URL.", "display_name": "Langwatch Evaluator"}, "selected": true, "width": 384, "height": 550, "positionAbsolute": {"x": 2018.1907464472497, "y": -783.5610398861654}, "dragging": false}], "edges": [{"source": "Prompt-2dgP5", "sourceHandle": "{\u0153dataType\u0153:\u0153Prompt\u0153,\u0153id\u0153:\u0153Prompt-2dgP5\u0153,\u0153name\u0153:\u0153prompt\u0153,\u0153output_types\u0153:[\u0153Message\u0153]}", "target": "ToolCallingAgent-YNHfV", "targetHandle": "{\u0153fieldName\u0153:\u0153system_prompt\u0153,\u0153id\u0153:\u0153ToolCallingAgent-YNHfV\u0153,\u0153inputTypes\u0153:[\u0153Message\u0153],\u0153type\u0153:\u0153str\u0153}", "data": {"targetHandle": {"fieldName": "system_prompt", "id": "ToolCallingAgent-YNHfV", "inputTypes": ["Message"], "type": "str"}, "sourceHandle": {"dataType": "Prompt", "id": "Prompt-2dgP5", "name": "prompt", "output_types": ["Message"]}}, "id": "reactflow__edge-Prompt-2dgP5{\u0153dataType\u0153:\u0153Prompt\u0153,\u0153id\u0153:\u0153Prompt-2dgP5\u0153,\u0153name\u0153:\u0153prompt\u0153,\u0153output_types\u0153:[\u0153Message\u0153]}-ToolCallingAgent-YNHfV{\u0153fieldName\u0153:\u0153system_prompt\u0153,\u0153id\u0153:\u0153ToolCallingAgent-YNHfV\u0153,\u0153inputTypes\u0153:[\u0153Message\u0153],\u0153type\u0153:\u0153str\u0153}", "className": "", "animated": false}, {"source": "ChatInput-N93NG", "sourceHandle": "{\u0153dataType\u0153:\u0153ChatInput\u0153,\u0153id\u0153:\u0153ChatInput-N93NG\u0153,\u0153name\u0153:\u0153message\u0153,\u0153output_types\u0153:[\u0153Message\u0153]}", "target": "ToolCallingAgent-YNHfV", "targetHandle": "{\u0153fieldName\u0153:\u0153input_value\u0153,\u0153id\u0153:\u0153ToolCallingAgent-YNHfV\u0153,\u0153inputTypes\u0153:[\u0153Message\u0153],\u0153type\u0153:\u0153str\u0153}", "data": {"targetHandle": {"fieldName": "input_value", "id": "ToolCallingAgent-YNHfV", "inputTypes": ["Message"], "type": "str"}, "sourceHandle": {"dataType": "ChatInput", "id": "ChatInput-N93NG", "name": "message", "output_types": ["Message"]}}, "id": "reactflow__edge-ChatInput-N93NG{\u0153dataType\u0153:\u0153ChatInput\u0153,\u0153id\u0153:\u0153ChatInput-N93NG\u0153,\u0153name\u0153:\u0153message\u0153,\u0153output_types\u0153:[\u0153Message\u0153]}-ToolCallingAgent-YNHfV{\u0153fieldName\u0153:\u0153input_value\u0153,\u0153id\u0153:\u0153ToolCallingAgent-YNHfV\u0153,\u0153inputTypes\u0153:[\u0153Message\u0153],\u0153type\u0153:\u0153str\u0153}", "selected": false, "className": "", "animated": false}, {"source": "ToolCallingAgent-YNHfV", "sourceHandle": "{\u0153dataType\u0153:\u0153ToolCallingAgent\u0153,\u0153id\u0153:\u0153ToolCallingAgent-YNHfV\u0153,\u0153name\u0153:\u0153response\u0153,\u0153output_types\u0153:[\u0153Message\u0153]}", "target": "ChatOutput-rvvAN", "targetHandle": "{\u0153fieldName\u0153:\u0153input_value\u0153,\u0153id\u0153:\u0153ChatOutput-rvvAN\u0153,\u0153inputTypes\u0153:[\u0153Message\u0153],\u0153type\u0153:\u0153str\u0153}", "data": {"targetHandle": {"fieldName": "input_value", "id": "ChatOutput-rvvAN", "inputTypes": ["Message"], "type": "str"}, "sourceHandle": {"dataType": "ToolCallingAgent", "id": "ToolCallingAgent-YNHfV", "name": "response", "output_types": ["Message"]}}, "id": "reactflow__edge-ToolCallingAgent-YNHfV{\u0153dataType\u0153:\u0153ToolCallingAgent\u0153,\u0153id\u0153:\u0153ToolCallingAgent-YNHfV\u0153,\u0153name\u0153:\u0153response\u0153,\u0153output_types\u0153:[\u0153Message\u0153]}-ChatOutput-rvvAN{\u0153fieldName\u0153:\u0153input_value\u0153,\u0153id\u0153:\u0153ChatOutput-rvvAN\u0153,\u0153inputTypes\u0153:[\u0153Message\u0153],\u0153type\u0153:\u0153str\u0153}", "className": "", "animated": false}, {"source": "OpenAIModel-mIrVZ", "sourceHandle": "{\u0153dataType\u0153:\u0153OpenAIModel\u0153,\u0153id\u0153:\u0153OpenAIModel-mIrVZ\u0153,\u0153name\u0153:\u0153model_output\u0153,\u0153output_types\u0153:[\u0153LanguageModel\u0153]}", "target": "ToolCallingAgent-YNHfV", "targetHandle": "{\u0153fieldName\u0153:\u0153llm\u0153,\u0153id\u0153:\u0153ToolCallingAgent-YNHfV\u0153,\u0153inputTypes\u0153:[\u0153LanguageModel\u0153],\u0153type\u0153:\u0153other\u0153}", "data": {"targetHandle": {"fieldName": "llm", "id": "ToolCallingAgent-YNHfV", "inputTypes": ["LanguageModel"], "type": "other"}, "sourceHandle": {"dataType": "OpenAIModel", "id": "OpenAIModel-mIrVZ", "name": "model_output", "output_types": ["LanguageModel"]}}, "id": "reactflow__edge-OpenAIModel-mIrVZ{\u0153dataType\u0153:\u0153OpenAIModel\u0153,\u0153id\u0153:\u0153OpenAIModel-mIrVZ\u0153,\u0153name\u0153:\u0153model_output\u0153,\u0153output_types\u0153:[\u0153LanguageModel\u0153]}-ToolCallingAgent-YNHfV{\u0153fieldName\u0153:\u0153llm\u0153,\u0153id\u0153:\u0153ToolCallingAgent-YNHfV\u0153,\u0153inputTypes\u0153:[\u0153LanguageModel\u0153],\u0153type\u0153:\u0153other\u0153}", "className": "", "animated": false}, {"source": "TavilySearch-1Ar3w", "sourceHandle": "{\u0153dataType\u0153:\u0153TavilySearch\u0153,\u0153id\u0153:\u0153TavilySearch-1Ar3w\u0153,\u0153name\u0153:\u0153api_build_tool\u0153,\u0153output_types\u0153:[\u0153Tool\u0153]}", "target": "ToolCallingAgent-YNHfV", "targetHandle": "{\u0153fieldName\u0153:\u0153tools\u0153,\u0153id\u0153:\u0153ToolCallingAgent-YNHfV\u0153,\u0153inputTypes\u0153:[\u0153Tool\u0153,\u0153BaseTool\u0153],\u0153type\u0153:\u0153other\u0153}", "data": {"targetHandle": {"fieldName": "tools", "id": "ToolCallingAgent-YNHfV", "inputTypes": ["Tool", "BaseTool"], "type": "other"}, "sourceHandle": {"dataType": "TavilySearch", "id": "TavilySearch-1Ar3w", "name": "api_build_tool", "output_types": ["Tool"]}}, "id": "reactflow__edge-TavilySearch-1Ar3w{\u0153dataType\u0153:\u0153TavilySearch\u0153,\u0153id\u0153:\u0153TavilySearch-1Ar3w\u0153,\u0153name\u0153:\u0153api_build_tool\u0153,\u0153output_types\u0153:[\u0153Tool\u0153]}-ToolCallingAgent-YNHfV{\u0153fieldName\u0153:\u0153tools\u0153,\u0153id\u0153:\u0153ToolCallingAgent-YNHfV\u0153,\u0153inputTypes\u0153:[\u0153Tool\u0153,\u0153BaseTool\u0153],\u0153type\u0153:\u0153other\u0153}", "animated": false, "className": ""}, {"source": "ChatOutput-rvvAN", "sourceHandle": "{\u0153dataType\u0153:\u0153ChatOutput\u0153,\u0153id\u0153:\u0153ChatOutput-rvvAN\u0153,\u0153name\u0153:\u0153message\u0153,\u0153output_types\u0153:[\u0153Message\u0153]}", "target": "LangWatchEvaluatorComponent-lc31r", "targetHandle": "{\u0153fieldName\u0153:\u0153answer\u0153,\u0153id\u0153:\u0153LangWatchEvaluatorComponent-lc31r\u0153,\u0153inputTypes\u0153:[\u0153Message\u0153],\u0153type\u0153:\u0153str\u0153}", "data": {"targetHandle": {"fieldName": "answer", "id": "LangWatchEvaluatorComponent-lc31r", "inputTypes": ["Message"], "type": "str"}, "sourceHandle": {"dataType": "ChatOutput", "id": "ChatOutput-rvvAN", "name": "message", "output_types": ["Message"]}}, "className": "", "animated": false, "id": "reactflow__edge-ChatOutput-rvvAN{\u0153dataType\u0153:\u0153ChatOutput\u0153,\u0153id\u0153:\u0153ChatOutput-rvvAN\u0153,\u0153name\u0153:\u0153message\u0153,\u0153output_types\u0153:[\u0153Message\u0153]}-LangWatchEvaluatorComponent-lc31r{\u0153fieldName\u0153:\u0153answer\u0153,\u0153id\u0153:\u0153LangWatchEvaluatorComponent-lc31r\u0153,\u0153inputTypes\u0153:[\u0153Message\u0153],\u0153type\u0153:\u0153str\u0153}"}, {"source": "ChatInput-N93NG", "sourceHandle": "{\u0153dataType\u0153:\u0153ChatInput\u0153,\u0153id\u0153:\u0153ChatInput-N93NG\u0153,\u0153name\u0153:\u0153message\u0153,\u0153output_types\u0153:[\u0153Message\u0153]}", "target": "LangWatchEvaluatorComponent-lc31r", "targetHandle": "{\u0153fieldName\u0153:\u0153question\u0153,\u0153id\u0153:\u0153LangWatchEvaluatorComponent-lc31r\u0153,\u0153inputTypes\u0153:[\u0153Message\u0153],\u0153type\u0153:\u0153str\u0153}", "data": {"targetHandle": {"fieldName": "question", "id": "LangWatchEvaluatorComponent-lc31r", "inputTypes": ["Message"], "type": "str"}, "sourceHandle": {"dataType": "ChatInput", "id": "ChatInput-N93NG", "name": "message", "output_types": ["Message"]}}, "className": "", "animated": false, "id": "reactflow__edge-ChatInput-N93NG{\u0153dataType\u0153:\u0153ChatInput\u0153,\u0153id\u0153:\u0153ChatInput-N93NG\u0153,\u0153name\u0153:\u0153message\u0153,\u0153output_types\u0153:[\u0153Message\u0153]}-LangWatchEvaluatorComponent-lc31r{\u0153fieldName\u0153:\u0153question\u0153,\u0153id\u0153:\u0153LangWatchEvaluatorComponent-lc31r\u0153,\u0153inputTypes\u0153:[\u0153Message\u0153],\u0153type\u0153:\u0153str\u0153}"}], "viewport": {"x": 130.06888007455996, "y": 481.5280870801688, "zoom": 0.36836018427727496}}, "user_id": "695dc54b-da9e-4f55-82e3-01e9e2b37ab7", "folder_id": "4cd6715c-c046-4365-bb5e-e76d4be5032e"}